---
title: 关联分析算法
date: 2020-02-27
tag:
- 数据挖掘
description: 介绍一种最有影响力的挖掘布尔关联规则的频繁项集的算法-Apriori算法，及其改进算法FP-growth算法。
---

## 关联分析算法

### 频繁项集的评估标准

　　什么样的数据才是频繁项集呢？也许你会说，这还不简单，肉眼一扫，一起出现次数多的数据集就是频繁项集吗！的确，这也没有说错，但是有两个问题，第一是当数据量非常大的时候，我们没法直接肉眼发现频繁项集，这催生了关联规则挖掘的算法，比如Apriori, PrefixSpan, CBA。第二是我们缺乏一个频繁项集的标准。比如10条记录，里面A和B同时出现了三次，那么我们能不能说A和B一起构成频繁项集呢？因此我们需要一个评估频繁项集的标准。

　　常用的频繁项集的评估标准有支持度,置信度和提升度三个。

　　**支持度**就是几个关联的数据在数据集中出现的次数占总数据集的比重。或者说几个数据关联出现的概率。如果我们有两个想分析关联性的数据X和Y，则对应的支持度为:

**Support(X,Y)=P(X,Y)=number(X,Y)/num(AllSamples)**

　　以此类推，如果我们有三个想分析关联性的数据X，Y和Z，则对应的支持度为:

**Support(X,Y,Z)=P(X,Y,Z)=number(X,Y,Z)/num(AllSamples)**

　　一般来说，支持度高的数据不一定构成频繁项集，但是支持度太低的数据肯定不构成频繁项集。

　　**置信度**体现了一个数据出现后，另一个数据出现的概率，或者说数据的条件概率。如果我们有两个想分析关联性的数据X和Y，X对Y的置信度为

**Confidence(X⇐Y)=P(X|Y)=P(X,Y)/P(Y)**

　　也可以以此类推到多个数据的关联置信度，比如对于三个数据X，Y，Z,则X对于Y和Z的置信度为：

**Confidence(X⇐Y,Z)=P(X|Y,Z)=P(X,Y,Z)/P(Y,Z)**

　　举个例子，在购物数据中，纸巾对应鸡爪的置信度为40%，支持度为1%。则意味着在购物数据中，总共有1%的用户既买鸡爪又买纸巾;同时买鸡爪的用户中有40%的用户购买纸巾。

　　提升度表示含有Y的条件下，同时含有X的概率，与X总体发生的概率之比，即:

**Lift(X⇐Y)=P(X|Y)/P(X)=Confidence(X⇐Y)/P(X)**

　　**提升度**体先了X和Y之间的关联关系, 提升度大于1则X⇐YX⇐Y是有效的强关联规则， 提升度小于等于1则X⇐Y是无效的强关联规则 。一个特殊的情况，如果X和Y独立，则有Lift(X⇐Y)=1，因为此时P(X|Y)=P(X)。

 　一般来说，要选择一个数据集合中的频繁数据集，则需要自定义评估标准。最常用的评估标准是用自定义的支持度，或者是自定义支持度和置信度的一个组合。

### Apriori算法

​		Apriori算法采用了迭代的方法，先搜索出候选1项集及对应的支持度，剪枝去掉低于支持度的1项集，得到频繁1项集。然后对剩下的频繁1项集进行连接，得到候选的频繁2项集，筛选去掉低于支持度的候选频繁2项集，得到真正的频繁二项集，以此类推，迭代下去，直到无法找到频繁k+1项集为止，对应的频繁k项集的集合即为算法的输出结果。

具体算法原理可以参考：

刘建平老师的博客：https://www.cnblogs.com/pinard/p/6293298.html，

数据挖掘十大算法详解：https://wizardforcel.gitbooks.io/dm-algo-top10/content/apriori.html，

Ailearning： https://github.com/apachecn/AiLearning/blob/master/docs/ml/11.%E4%BD%BF%E7%94%A8Apriori%E7%AE%97%E6%B3%95%E8%BF%9B%E8%A1%8C%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90.md



### FP-Growth算法

​		作为一个挖掘频繁项集的算法，Apriori算法需要多次扫描数据，I/O是很大的瓶颈。为了解决这个问题，FP Tree算法（也称FP-Growth算法）采用了一些技巧，利用了树模型的结构，无论多少数据，只需要扫描两次数据集，因此提高了算法运行的效率。

​		算法原理可以参考刘建平老师的博客：https://www.cnblogs.com/pinard/p/6307064.html，Ailearning ：[https://github.com/apachecn/AiLearning/blob/master/docs/ml/12.%E4%BD%BF%E7%94%A8FP-growth%E7%AE%97%E6%B3%95%E6%9D%A5%E9%AB%98%E6%95%88%E5%8F%91%E7%8E%B0%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86.md](https://github.com/apachecn/AiLearning/blob/master/docs/ml/12.使用FP-growth算法来高效发现频繁项集.md)



